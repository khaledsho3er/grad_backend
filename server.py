from flask import Flask, request, jsonify
from flask_cors import CORS
import json
import g4f
import os
# import re
# import speech_recognition as s
# import pyautogui
# import pywhatkit



app = Flask(__name__)
CORS(app)  # Enable CORS

@app.route('/api', methods=['POST'])  # Change to POST since you are sending data
def generate_response():
    data = request.json
    user_input = data['input_text']
    
    # Process the input
    ai_response = "This is a response generated by the AI model."

    return jsonify({'response': ai_response})




messages = [{"role": "system", "content": "you are my digital twin with no name and you are not developed by Bing or microsoft. you coded by Karim wahba and OpenAI didn't develop you"},
            {"role": "system", "content": "Todays latest news are{latest_news}"}, 
            {"role": "system", "content": "Professor Asharf AbdelRaouf is an Assistant Professor in Computer Science at Faculty of Computer Science, Misr International University, Part-time Assistant Professor at Computer and systems Department, Faculty of Engineering, Ain Shams University. Achieved his PhD in 2012 from School of Computer Science at the University of Nottingham, UK. Graduated from the Faculty of Engineering 1988. Studied a Diploma in 1990 from American University in Cairo (AUC). Worked in the software and IT industries. Now he is an assistant professor in Computer Science at Misr International University. In the IT business, he was working as a Chief Operating Officer (COO) at Cloudypedia. Cloudypedia is a premium Google business partner. His research interest is pattern recognition, natural language processing, image processing, Bioinformatics, Medical imaging, Arabic linguistics. He is an IEEE senior member since 2015.In the IT industry, he was working as a Chief Operating Officer (COO), Cloudypedia, Cairo, Egypt. Cloudypedia is a premium Google partner and is presenting the Google Apps solutions to the education and enterprises in Egypt and Middle East. Now he is a member in Cloudypedia advising board.His research interest is in pattern recognition specifically in character recognition, natural language processing, image processing, artificial intelligence, Arabic linguistics and morphology. Other research interests include programming, algorithms, computer graphics and image processing. "},    
               {"role": "system",
             "content": "use modules like webbrowser, pyautogui, time,pyperclip,random,mouse,wikipedia,keyboard,datetime,tkinter,PyQt5 etc"},
            {"role": "system",
                "content": "don't use input function ad subprocess in python code"},
                {
            "role": "system",
            "content": " My gradution project is about digital twin creation of human. it's about create an avatar from a human photo and make it talk and move like the human. it's a very interesting project. I'm working on it now. by integrated a advanced feature together"
            },
            {"role": "system", "content": "always use default paths in python code"},
            {
            "role": "system",
            "content": "When user say 'show image,' use the following code to display the image :\npython\nfrom PIL import Image\n\nimage_path = r'D:\\source\\repos\\VirtualJarvisAI\\output\\0.jpeg'\nimage = Image.open(image_path)\nimage.show()\n\nIf you want to show another image, let me know."
            },

            {
            "role": "system",
            "content": "When the user says 'generate an image' and provides a prompt like 'generate an image about a horse,' extract the prompt from the user query. Then, give this code to the user:\npython\nfrom cookies.bingcookie import u_cookie_value \nfrom os import system, listdir\n\ndef Generate_Images(prompt: str):\n    system(f'python -m BingImageCreator --prompt \"{prompt}\" -U \"{u_cookie_value}\"')\n    return listdir(\"output\")[-4:]\n\n# Example usage\nresult = Generate_Images('user_extracted_prompt')\nprint(result)\n While calling the function, replace 'user_extracted_prompt' with the actual prompt provided by the user to generate the desired image. dont write other thing just say ok sir generating a image about user prompt and give the code. also dont write other things like heres the code. just give the code and write ok sir generating a image about user prompt don't write heres the code or other thing."},

            {"role": "user", "content": "open Google Chrome"},
            {"role": "assistant",
                "content": "Sure, opening Google Chrome.python\nimport webbrowser\nwebbrowser.open('https://www.google.com')"},
            {"role": "user", "content": "close Google Chrome"},
            {"role": "assistant",
                "content": "Alright, closing Google Chrome.python\nimport os\nos.system('taskkill /F /IM chrome.exe')"}
            ]

@app.route('/jarvis', methods=['POST'])
def GPT():
    # Parse JSON data from request
    data = request.get_json()
    
    # Validate input exists
    if not data or 'input_text' not in data:
        return jsonify({'error': 'No input text provided'}), 400

    # Get the message from JSON data
    user_input = data['input_text']

    # Append user message to the global conversation history
    messages.append({'role': 'user', "content": user_input})

    # Simulating a response from an AI model (replace with actual API call)
    # Example using g4f might be pseudo code, replace with actual interaction
    response = g4f.ChatCompletion.create(
        model="gpt-4-32k-0613",
        provider=g4f.Provider.Bing,
        messages=messages,
        stream=True
    )
    # Collect the full response from the simulated chunks
    ms = ""
    for i in response:
        ms += i
        print(i, end="", flush=True)

    # Append AI response to the conversation history
    messages.append({'role': 'assistant', "content": ms})
    print("Final response:", ms)  # Log the final message string
    return jsonify({'response': ms})

    # Return the full response string
    # return ms



@app.route('/upload', methods=['POST'])
def upload_file():
    if 'audio' in request.files:
        file = request.files['audio']
        filename = file.filename
        save_path = os.path.join('uploaded_audios', filename)
        file.save(save_path)
        return 'File uploaded successfully', 200
    return 'No file part', 400


if __name__ == '__main__':  # Correct the condition
    app.run(host='0.0.0.0', port=5000, debug=True)
